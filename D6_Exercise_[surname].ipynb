{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 6 Exercise\n",
    "A. (25 mins) **Genre Classification (Individual)**\n",
    "\n",
    "   1. Choose up to 6 music genres and obtain track data from the genre's top 20 most-followed playlists in Spotify. A group may distribute the data gathering task by assigning a genre to each person and then pooling all the gathered data in one shared folder. \n",
    "   Alternatively, you may also use the provided sample playlist data.\n",
    "    \n",
    "   2. Pick any 2 music genres as your groupings for the classification exercise and repeat Steps 1-7. Make sure to answer the guide questions for each step\n",
    "   \n",
    "   3. Increase the number of features included in the models and repeat Steps 1-7 (but skip code cells for plotting-- viz for >2D will not work). How does this affect the model scores? Find the combination of features that will give you the best accuracy score.\n",
    "   \n",
    "   4. CHALLENGE (optional) Modify the notebook to take in any 3 music genres as groupings and repeat Steps 1-7.\n",
    "\n",
    "B. (10 mins) **Group sharing**\n",
    "\n",
    "Take turns presenting this notebook with your code answer to the whole group. Be brief and discuss only your best result.\n",
    "\n",
    "-----\n",
    "\n",
    "2. *(Optional, but useful to do ahead for your sprint project)*\n",
    "\n",
    "    There are almost [innumerable](https://www.musicgenreslist.com/) named music genres online, but a summarized list  may be found [here](https://www.blisshq.com/music-library-management-blog/2011/01/25/fundamental-music-genre-list/).\n",
    "    \n",
    "    Can you build a model that can predict **at least 5 genres** listed in the latter with **>70% classification accuracy**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Submit this notebook at the end of class time*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:23:36.241488Z",
     "start_time": "2021-12-28T09:23:34.229735Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read and check values of 2 playlist sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:23:36.257425Z",
     "start_time": "2021-12-28T09:23:36.241488Z"
    }
   },
   "outputs": [],
   "source": [
    "#set keyword\n",
    "KEYWORD1='rock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:23:36.349375Z",
     "start_time": "2021-12-28T09:23:36.299402Z"
    }
   },
   "outputs": [],
   "source": [
    "# read and process the playlist data for keyword\n",
    "playlist1_df = pd.read_csv('data/playlists/'+KEYWORD1+'_playlist_data.csv')\n",
    "playlist1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:23:36.365362Z",
     "start_time": "2021-12-28T09:23:36.353370Z"
    }
   },
   "outputs": [],
   "source": [
    "playlist1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:23:36.540261Z",
     "start_time": "2021-12-28T09:23:36.370359Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read and process the playlist data for keyword\n",
    "tracks1_df = pd.read_csv('data/playlists/'+KEYWORD1+'_playlist_tracks_data.csv')\\\n",
    "                .merge(pd.read_csv('data/playlists/'+KEYWORD1+'_playlist_tracks.csv')[['track_id','playlist_id','playlist_name']],\\\n",
    "                      on='track_id',how='left')\n",
    "#make duration ms to minutes\n",
    "tracks1_df['duration_mins']=tracks1_df['duration']/60000\n",
    "#tag genre with keyword\n",
    "tracks1_df['genre']=KEYWORD1\n",
    "tracks1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:23:36.555258Z",
     "start_time": "2021-12-28T09:23:36.543261Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:23:36.587235Z",
     "start_time": "2021-12-28T09:23:36.562252Z"
    }
   },
   "outputs": [],
   "source": [
    "# How many unique tracks are in playlist set 1?\n",
    "len(tracks1_df['track_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:23:36.966018Z",
     "start_time": "2021-12-28T09:23:36.590234Z"
    }
   },
   "outputs": [],
   "source": [
    "# What is the distribution of playlist set 1's total tracks?\n",
    "playlist1_df['playlist_total_tracks'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:23:36.982012Z",
     "start_time": "2021-12-28T09:23:36.969018Z"
    }
   },
   "outputs": [],
   "source": [
    "len(playlist1_df[playlist1_df['playlist_total_tracks']>10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:23:37.406775Z",
     "start_time": "2021-12-28T09:23:36.985007Z"
    }
   },
   "outputs": [],
   "source": [
    "# What is the distribution of playlist set 1's total tracks?\n",
    "playlist1_df['total_followers'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:23:37.421757Z",
     "start_time": "2021-12-28T09:23:37.412763Z"
    }
   },
   "outputs": [],
   "source": [
    "###################### set keyword\n",
    "KEYWORD2='R&B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:23:37.468752Z",
     "start_time": "2021-12-28T09:23:37.424756Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read and process the playlist data for keyword\n",
    "playlist2_df = pd.read_csv('data/playlists/'+KEYWORD2+'_playlist_data.csv')\n",
    "playlist2_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:23:37.498730Z",
     "start_time": "2021-12-28T09:23:37.478731Z"
    }
   },
   "outputs": [],
   "source": [
    "playlist2_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:23:37.623642Z",
     "start_time": "2021-12-28T09:23:37.505711Z"
    }
   },
   "outputs": [],
   "source": [
    "# read and process the playlist data for keyword\n",
    "tracks2_df = pd.read_csv('data/playlists/'+KEYWORD2+'_playlist_tracks_data.csv')\\\n",
    "                .merge(pd.read_csv('data/playlists/'+KEYWORD2+'_playlist_tracks.csv')[['track_id','playlist_id','playlist_name']],\\\n",
    "                      on='track_id',how='left')\n",
    "#make duration ms to minutes\n",
    "tracks2_df['duration_mins']=tracks2_df['duration']/60000\n",
    "#tag genre with keyword\n",
    "tracks2_df['genre']=KEYWORD2\n",
    "tracks2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:23:37.639634Z",
     "start_time": "2021-12-28T09:23:37.628668Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks2_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:23:37.655624Z",
     "start_time": "2021-12-28T09:23:37.643631Z"
    }
   },
   "outputs": [],
   "source": [
    "# How many unique tracks are in playlist 2?\n",
    "len(tracks2_df['track_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compare histograms of 2 playlist sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:26:27.870279Z",
     "start_time": "2021-12-28T09:23:37.800541Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in ['danceability', 'energy', 'key',\n",
    "       'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "       'liveness', 'valence', 'tempo']:\n",
    "    fig,ax = plt.subplots()\n",
    "    \n",
    "    sns.histplot(tracks1_df[col], ax=ax, label= KEYWORD1, kde=True, color='C0', edgecolor='None')\n",
    "    sns.histplot(tracks2_df[col], ax=ax, label= KEYWORD2,  kde=True, color='C1', edgecolor='None')\n",
    "    plt.title(\"%s vs %s: %s \" % (KEYWORD1,KEYWORD2,col))\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Q: What feature/s best distinguish the 2 categories from each other? Does it make sense to use this as a feature for a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()   #RobustScaler would also work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:26:27.916910Z",
     "start_time": "2021-12-28T09:26:27.872934Z"
    }
   },
   "outputs": [],
   "source": [
    "#get union of two playlist tracks list\n",
    "tracks_df = pd.concat([tracks1_df,tracks2_df])\n",
    "tracks1_df.shape, tracks2_df.shape, tracks_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:26:27.980877Z",
     "start_time": "2021-12-28T09:26:27.925905Z"
    }
   },
   "outputs": [],
   "source": [
    "#retain only distinct tracks per keyword\n",
    "tracks_df =tracks_df.drop_duplicates(subset='track_id')\n",
    "tracks_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:26:29.320375Z",
     "start_time": "2021-12-28T09:26:27.987868Z"
    }
   },
   "outputs": [],
   "source": [
    "#Normalize loudness\n",
    "tracks_df['loudness'] = scaler.fit_transform(tracks_df[['loudness']])\n",
    "tracks_df['loudness'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:26:29.351356Z",
     "start_time": "2021-12-28T09:26:29.323377Z"
    }
   },
   "outputs": [],
   "source": [
    "#Normalize tempo\n",
    "tracks_df['tempo'] =  scaler.fit_transform(tracks_df[['tempo']])\n",
    "#check\n",
    "tracks_df['tempo'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:26:29.385337Z",
     "start_time": "2021-12-28T09:26:29.355370Z"
    }
   },
   "outputs": [],
   "source": [
    "# map genres to numbers\n",
    "tracks_df['genre_id'] = tracks_df['genre'].map({KEYWORD1:1,KEYWORD2:2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preview possible classification results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Q: Pick the 2 best distinguishing features of the 2 playlist sets and plot each row as a scatterplot/distplot colored by genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['X','Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=tracks_df, x=feature_cols[0], y=feature_cols[1], hue='genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax= fig.add_subplot(111)\n",
    "\n",
    "colormaps = ['Blues','Oranges']\n",
    "for n,genre in enumerate([KEYWORD1,KEYWORD2]):\n",
    "    df=tracks_df[tracks_df['genre']==genre]\n",
    "    sns.kdeplot(x=df[feature_cols[0]],y=df[feature_cols[1]], ax=ax,\\\n",
    "                shade=True, alpha=0.5, cmap=colormaps[n])\n",
    "\n",
    "#hack for proper legend render\n",
    "sns.scatterplot(data=tracks_df, x=feature_cols[0], y=feature_cols[1], hue='genre', s=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q: How would you interpret the resulting scatterplot/distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:20:49.177733Z",
     "start_time": "2021-12-29T16:20:49.165741Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import accuracy_score,roc_curve, auc, confusion_matrix, classification_report,\\\n",
    "    plot_confusion_matrix, plot_roc_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Tuning: kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select audio features to use for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T16:57:48.777625Z",
     "start_time": "2021-12-28T16:57:48.761637Z"
    }
   },
   "outputs": [],
   "source": [
    "# create feature matrix (X)\n",
    "# pick energy and tempo as features\n",
    "\n",
    "X = tracks_df[feature_cols]\n",
    "y = tracks_df['genre_id']\n",
    "print(len(X),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T17:33:04.906678Z",
     "start_time": "2021-12-28T17:32:56.085654Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_neighbors = np.arange(2,51)\n",
    "KFOLDS = 5\n",
    "\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "\n",
    "for K in n_neighbors:\n",
    "    print('Fitting KNN with K=%d ...' % K, end='')\n",
    "    #initialize model\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=K)\n",
    "    # get accuracy metric across train-test sets generated using k-folds\n",
    "    scores = cross_val_score(knn_model, X, y, cv=KFOLDS, scoring='accuracy')\n",
    "    # overall accuracy score of K is mean of accuracy scores per k-fold\n",
    "    # std dev of scores across folds must be a minimum\n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose optimal value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T17:51:05.501674Z",
     "start_time": "2021-12-28T17:51:05.102594Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# determining best K\n",
    "idx_max_accuracy = cv_scores_mean.index(max(cv_scores_mean))\n",
    "optimal_K = n_neighbors[idx_max_accuracy]\n",
    "print(\"The optimal number of neighbors is %0.2f with accuracy %0.2f\" % (optimal_K, cv_scores_mean[idx_max_accuracy]))\n",
    "\n",
    "# plot metrics \n",
    "fig,axs = plt.subplots(1,2, figsize=(11,4))\n",
    "axs[0].plot(n_neighbors, cv_scores_mean)\n",
    "axs[0].plot(optimal_K,max(cv_scores_mean), marker=\"o\", ms=7, color='r')\n",
    "axs[0].set_xlabel(\"Number of Neighbors K\")\n",
    "axs[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "axs[1].plot(n_neighbors, cv_scores_std)\n",
    "axs[1].plot(optimal_K,cv_scores_std[idx_min_mse], marker=\"o\", ms=7, color='r')\n",
    "axs[1].set_xlabel(\"Number of Neighbors K\")\n",
    "axs[1].set_ylabel(\"Accuracy standard deviation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out optimal model with entire length of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:11:24.205836Z",
     "start_time": "2021-12-29T16:11:24.138876Z"
    }
   },
   "outputs": [],
   "source": [
    "#initialize KNN with optimal K\n",
    "knn_optimal_model = KNeighborsClassifier(n_neighbors=optimal_K )\n",
    "# fitting the model with entire dataset\n",
    "knn_optimal_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T17:42:35.537136Z",
     "start_time": "2021-12-28T17:42:35.351532Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict the response\n",
    "pred = knn_optimal_model.predict(X)\n",
    "# evaluate accuracy\n",
    "acc = accuracy_score(y, pred) * 100\n",
    "print('\\nThe accuracy of the knn classifier for the full dataset using k = %d is %f%%' % (optimal_K, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Tuning: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T11:10:29.642098Z",
     "start_time": "2021-12-29T11:10:29.597127Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/svm/plot_iris_svc.html#sphx-glr-auto-examples-svm-plot-iris-svc-py\n",
    "def make_meshgrid(x, y, h=.02):\n",
    "    \"\"\"Create a mesh of points to plot in\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: data to base x-axis meshgrid on\n",
    "    y: data to base y-axis meshgrid on\n",
    "    h: stepsize for meshgrid, optional\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xx, yy : ndarray\n",
    "    \"\"\"\n",
    "    xmgn= (x.max()-x.min())*0.25\n",
    "    ymgn = (y.max()-y.min())*0.25\n",
    "    \n",
    "    x_min, x_max = x.min() - xmgn, x.max() + xmgn\n",
    "    y_min, y_max = y.min() - ymgn, y.max() + ymgn\n",
    "    \n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, xlims,ylims, **params):\n",
    "    \"\"\"Plot the decision boundaries for a classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax: matplotlib axes object\n",
    "    clf: a classifier\n",
    "    xx: meshgrid ndarray\n",
    "    yy: meshgrid ndarray\n",
    "    params: dictionary of params to pass to contourf, optional\n",
    "    \"\"\"\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    ax.set_ylim(ylims)\n",
    "    ax.set_xlim(xlims)\n",
    "    \n",
    "    return out\n",
    "\n",
    "#visualize support vectors\n",
    "def plot_vector_bounds(X,svm_model, show_points=True):\n",
    "    fig,ax=plt.subplots()\n",
    "    \n",
    "    X0 = X.to_numpy()[:, 0]\n",
    "    X1 = X.to_numpy()[:, 1]\n",
    "    xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "    plot_contours(ax, svm_model, xx, yy, [0,1],[0,1],\n",
    "                      cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    if show_points:\n",
    "        ax.scatter(X0, X1, c=y,cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "    ax.set_xlabel(X.columns[0])\n",
    "    ax.set_ylabel(X.columns[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T17:55:44.434422Z",
     "start_time": "2021-12-28T17:55:44.423428Z"
    }
   },
   "outputs": [],
   "source": [
    "# create feature matrix (X)\n",
    "feature_cols = ['energy','tempo']\n",
    "X = tracks_df[feature_cols]\n",
    "y = tracks_df['genre_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Q: Go back to the scatter/distplot. What seems to be the appropriate kernel type to use for the classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a **linear** kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T11:17:29.710024Z",
     "start_time": "2021-12-29T11:17:29.689040Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_scores(cv_scores_mean,cv_scores_std):\n",
    "    fig,axs = plt.subplots(1,2, figsize=(11,4))\n",
    "    \n",
    "    x = np.arange(len(cv_scores_mean))\n",
    "    max_mean_score_idx = cv_scores_mean.argmax()\n",
    "    \n",
    "    axs[0].plot(x, cv_scores_mean, marker='.', lw=0)\n",
    "    axs[0].plot(x[max_mean_score_idx],max(cv_scores_mean), marker=\"o\", ms=7, color='r')\n",
    "    axs[0].set_xlabel(\"Model config type\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "    axs[1].plot(x, cv_scores_std, marker='.', lw=0)\n",
    "    axs[1].plot(x[max_mean_score_idx],cv_scores_std[max_mean_score_idx], marker=\"o\", ms=7, color='r')\n",
    "    axs[1].set_xlabel(\"Model config type\")\n",
    "    axs[1].set_ylabel(\"Accuracy standard deviation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T11:18:31.921600Z",
     "start_time": "2021-12-29T11:18:26.992961Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Linear model\n",
    "print('Fitting SVM with linear kernel...')\n",
    "\n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'kernel': ['linear']}\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 1, cv = KFOLDS )\n",
    "# fitting the model for grid search\n",
    "grid.fit(X, y)\n",
    "\n",
    "#get scores\n",
    "cv_scores_mean =  grid.cv_results_['mean_test_score']\n",
    "cv_scores_std = grid.cv_results_['std_test_score']\n",
    "max_mean_score_idx = cv_scores_mean.argmax()\n",
    "\n",
    "print('Best model config score is %f%% (vs. overall mean score: %f )' % (100*cv_scores_mean[max_mean_score_idx],\n",
    "                                                                        100*np.mean(cv_scores_mean)))\n",
    "print('Std of best model score across folds is %f (vs. overall mean std: %f )' %\\\n",
    "      (cv_scores_std[max_mean_score_idx], np.mean(cv_scores_std)))\n",
    "\n",
    "# get best model\n",
    "svm_model1 = grid.best_estimator_\n",
    "# fit model for entire data\n",
    "svm_model1.fit(X, y)\n",
    "pred1 = svm_model1.predict(X)\n",
    "acc = accuracy_score(y, pred1) * 100\n",
    "print('The accuracy of the SVM classifier for the full dataset is %f%%' % (acc))\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T11:18:32.348360Z",
     "start_time": "2021-12-29T11:18:31.924583Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot bounds\n",
    "#error: plot vector bounds only works w 2 input features\n",
    "plot_vector_bounds(X,svm_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T11:18:32.854050Z",
     "start_time": "2021-12-29T11:18:32.353338Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_scores(cv_scores_mean,cv_scores_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a **polynomial** kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T11:24:06.029510Z",
     "start_time": "2021-12-29T11:22:56.102793Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining parameter range\n",
    "print('Fitting SVM with a polynomial kernel...')\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'degree': np.arange(2,6),\n",
    "              'kernel': ['poly']}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 1, cv = KFOLDS )\n",
    "# fitting the model for grid search\n",
    "grid.fit(X, y)\n",
    "print('Best model is %s' % grid.best_estimator_)\n",
    "\n",
    "#get scores\n",
    "cv_scores_mean =  grid.cv_results_['mean_test_score']\n",
    "cv_scores_std = grid.cv_results_['std_test_score']\n",
    "max_mean_score_idx = cv_scores_mean.argmax()\n",
    "\n",
    "print('Best model config score is %f%% (vs. overall mean score: %f )' % (100*cv_scores_mean[max_mean_score_idx],\n",
    "                                                                        100*np.mean(cv_scores_mean)))\n",
    "print('Std of best model score across folds is %f (vs. overall mean std: %f )' %\\\n",
    "      (cv_scores_std[max_mean_score_idx], np.mean(cv_scores_std)))\n",
    "\n",
    "# get best model\n",
    "svm_model2 = grid.best_estimator_\n",
    "# fit model for entire data\n",
    "svm_model2.fit(X, y)\n",
    "pred2 = svm_model2.predict(X)\n",
    "acc = accuracy_score(y, pred2) * 100\n",
    "print('The accuracy of the SVM classifier for the full dataset is %f%%' % (acc))\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T11:26:07.985274Z",
     "start_time": "2021-12-29T11:26:07.609883Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot bounds\n",
    "#error: plot vector bounds only works w 2 input features\n",
    "plot_vector_bounds(X,svm_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T11:24:06.914433Z",
     "start_time": "2021-12-29T11:24:06.521228Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_scores(cv_scores_mean,cv_scores_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a **radial** kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T11:25:08.695350Z",
     "start_time": "2021-12-29T11:24:46.287726Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining parameter range\n",
    "print('Fitting SVM with a polynomial kernel...')\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 1, cv = KFOLDS )\n",
    "# fitting the model for grid search\n",
    "grid.fit(X, y)\n",
    "print('Best model is %s' % grid.best_estimator_)\n",
    "\n",
    "#get scores\n",
    "cv_scores_mean =  grid.cv_results_['mean_test_score']\n",
    "cv_scores_std = grid.cv_results_['std_test_score']\n",
    "max_mean_score_idx = cv_scores_mean.argmax()\n",
    "\n",
    "print('Best model config score is %f%% (vs. overall mean score: %f )' % (100*cv_scores_mean[max_mean_score_idx],\n",
    "                                                                        100*np.mean(cv_scores_mean)))\n",
    "print('Std of best model score across folds is %f (vs. overall mean std: %f )' %\\\n",
    "      (cv_scores_std[max_mean_score_idx], np.mean(cv_scores_std)))\n",
    "\n",
    "# get best model\n",
    "svm_model3 = grid.best_estimator_\n",
    "# fit model for entire data\n",
    "svm_model3.fit(X, y)\n",
    "pred3 = svm_model3.predict(X)\n",
    "acc = accuracy_score(y, pred3) * 100\n",
    "print('The accuracy of the SVM classifier for the full dataset is %f%%' % (acc))\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T11:25:41.009685Z",
     "start_time": "2021-12-29T11:25:40.521260Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot bounds\n",
    "plot_vector_bounds(X,svm_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T11:28:45.671426Z",
     "start_time": "2021-12-29T11:28:45.325616Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_scores(cv_scores_mean,cv_scores_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select best SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:37:03.612375Z",
     "start_time": "2021-12-29T16:37:01.758434Z"
    }
   },
   "outputs": [],
   "source": [
    "svm_optimal_model = svm_model2\n",
    "#set probability=True to view classification probabilities and refit\n",
    "svm_optimal_model.probability=True\n",
    "svm_optimal_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Q: Which between KNN and SVM performed better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:37:04.193045Z",
     "start_time": "2021-12-29T16:37:03.615372Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(svm_optimal_model,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:39:15.651582Z",
     "start_time": "2021-12-29T16:39:15.250832Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(knn_optimal_model,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:42:44.590574Z",
     "start_time": "2021-12-29T16:42:44.253768Z"
    }
   },
   "outputs": [],
   "source": [
    "print('-------------------------------------------------------------')\n",
    "print('KNN')\n",
    "print(classification_report(y,knn_optimal_model.predict(X)))\n",
    "print('-------------------------------------------------------------')\n",
    "print('SVM')\n",
    "print(classification_report(y,svm_optimal_model.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- accuracy = % correct genre classifications\n",
    "        all correct / all\n",
    "- precision =  % correct genre classifications given everything model classified as that genre, emphasizes false positives\n",
    "        TP/TP+FP \n",
    "- recall = % correct genre classifications given all actual tracks in the genre, emphasizes false negatives\n",
    "        TP/TP+FN\n",
    "- f1-score = weighted average of Precision and Recall\n",
    "        F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n",
    "- support = number of items in the class\n",
    "\n",
    "- macro ave = average of the unweighted mean per label\n",
    "- weighted ave = average of the weighted mean per label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:50:06.895411Z",
     "start_time": "2021-12-29T16:50:06.875404Z"
    }
   },
   "outputs": [],
   "source": [
    "#helper function\n",
    "def plot_ROC(model,X,y):\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    plot_roc_curve(model,X,y, ax=ax)\n",
    "    #y=x line\n",
    "    ax.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    #edit verbose legend\n",
    "    default_legend = ax.get_legend_handles_labels()[1][0]\n",
    "    ax.legend(labels=[default_legend.split(' (')[-1][:-1]],loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:50:07.476776Z",
     "start_time": "2021-12-29T16:50:07.201954Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_ROC(knn_optimal_model,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:50:07.840603Z",
     "start_time": "2021-12-29T16:50:07.504761Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_ROC(svm_optimal_model,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose optimal model among those above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_model = 'XXXXXXXXXXXXX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Verifying results using in-sample and out-of-sample predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In-sample**\n",
    "\n",
    "Check if predicted genres match the genre orinally tagged acc to the spotify playlist name. Focus on misclassified tracks with higher prediction probability to identify possible model improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:06:34.889313Z",
     "start_time": "2021-12-29T17:06:26.630878Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks_df['predicted_genre_id'] = tracks_df.apply(lambda x:  optimal_model.predict(x[feature_cols].values.reshape(1,-1))[0]\\\n",
    "                                               , axis=1)\n",
    "tracks_df['predicted_genre'] = tracks_df['predicted_genre_id'].map({1:KEYWORD1,2:KEYWORD2})\n",
    "tracks_df['predicted_genre_prob'] = tracks_df.apply(lambda x:  np.max(optimal_model.predict_proba(x[feature_cols].values.reshape(1,-1)))\\\n",
    "                                                    , axis=1)\n",
    "tracks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:08:21.058342Z",
     "start_time": "2021-12-29T17:08:20.820465Z"
    }
   },
   "outputs": [],
   "source": [
    "#View histogram of probabilities\n",
    "tracks_df['predicted_genre_prob'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check tracks mistakenly classified with but high probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:12:12.648162Z",
     "start_time": "2021-12-29T17:12:12.614186Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracks_df[(tracks_df['predicted_genre_id']!=tracks_df['genre_id'])&(tracks_df['predicted_genre_prob']>0.9)]\\\n",
    "        .sort_values('predicted_genre_prob', ascending=False)[['track_name','artist_name','genre','predicted_genre','predicted_genre_prob']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Out-of-sample**\n",
    "\n",
    "Check if best model correctly predicts the genre of a track in the Top 200 charts (assuming most are not in the playlist data). User may validate the results subjectively as a listener, or refer to another source by looking up the track in a genre-tagging site(e.g. https://www.chosic.com/music-genre-finder/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:14:27.146147Z",
     "start_time": "2021-12-29T17:14:27.079190Z"
    }
   },
   "outputs": [],
   "source": [
    "chart_tracks_df = pd.read_csv(\"data/spotify_daily_charts_tracks.csv\")\n",
    "chart_tracks_df = chart_tracks_df.dropna()\n",
    "chart_tracks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:14:27.489695Z",
     "start_time": "2021-12-29T17:14:27.467724Z"
    }
   },
   "outputs": [],
   "source": [
    "#scale tempo\n",
    "chart_tracks_df['tempo'] =  scaler.fit_transform(chart_tracks_df[['tempo']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:14:39.712921Z",
     "start_time": "2021-12-29T17:14:28.440619Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create columns matching the predicted genre and probability of the best model to each of the tracks in the charts\n",
    "chart_tracks_df['predicted_genre_id'] = chart_tracks_df.apply(lambda x:  optimal_model.predict(x[feature_cols].values.reshape(1,-1))[0]\\\n",
    "                                               , axis=1)\n",
    "chart_tracks_df['predicted_genre'] = chart_tracks_df['predicted_genre_id'].map({1:KEYWORD1,2:KEYWORD2})\n",
    "chart_tracks_df['predicted_genre_prob'] = chart_tracks_df.apply(lambda x:  np.max(optimal_model.predict_proba(x[feature_cols].values.reshape(1,-1)))\\\n",
    "                                                    , axis=1)\n",
    "chart_tracks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:14:39.728893Z",
     "start_time": "2021-12-29T17:14:39.715900Z"
    }
   },
   "outputs": [],
   "source": [
    "chart_tracks_df['predicted_genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:20:26.669598Z",
     "start_time": "2021-12-29T17:20:26.401751Z"
    }
   },
   "outputs": [],
   "source": [
    "#View histogram of probabilities\n",
    "chart_tracks_df['predicted_genre_prob'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q: Can you identify tracks that were misclassfied by the model?\n",
    "    Does it make sense that the model misclassfied the tracks given the model configuration? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:21:41.266871Z",
     "start_time": "2021-12-29T17:21:41.239882Z"
    }
   },
   "outputs": [],
   "source": [
    "#Check tracks classified with higher probability\n",
    "chart_tracks_df[chart_tracks_df['predicted_genre']=='rock'][['track_name','artist_name','predicted_genre','predicted_genre_prob']]\\\n",
    "            .sort_values(['predicted_genre_prob'],ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T17:21:42.108454Z",
     "start_time": "2021-12-29T17:21:42.070476Z"
    }
   },
   "outputs": [],
   "source": [
    "#Check tracks classified with higher probability\n",
    "chart_tracks_df[chart_tracks_df['predicted_genre']=='R&B'][['track_name','artist_name','predicted_genre','predicted_genre_prob']]\\\n",
    "            .sort_values(['predicted_genre_prob'],ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
